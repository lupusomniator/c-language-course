# Алгоритм Рабина-Карпа #
## Краткое введение ##
Шо это такое, этот ваш Рабин-Карп? Вроде ни рыба, ни мясо, а оказывается это целый алгоритм поиска шаблона в некоторой строке, изюминкой которого является использование скользящего хэширования для выполнения своей задачи. 
## Описание алгоритма ##
Нам выдаётся некоторый шаблон длиной **n**, который нам нужно найти в тексте или же в другой строке. Шаблоном может быть какой-то набор символов, набор слов и т.д. Хэш-функция, которой мы будем пользоваться, называется полиномиальной и базируется на принципах модульной арифметики, всё это для того, чтобы наш хэш (к слову, хэш - это какое-то число) не превратился в цифрового монстра, состоящего из десятков десятичных разрядов, а выглядит эта хэш-функция как-то так:

**hash(s[n]) = ((s[0] * 1) + (s[1] * p) + ... + (s[n-1] * p^(n-1))) mod q**;

Где **s[n]** - последоватльность символов, хэш которой надо вычислить, **s[i]** - какой-то символ, лежащий в нашей строке, **n** - длина этой последоватльности, **q** - большое простое число, 
**p** - натуральное число (**p** < **q**).
Мы заранее вычисляем хэш от нашего шаблона длиной **n** и запоминаем его. Далее считываем **n** символов из нашего текста и также вычисляем для этой последовавтельности хэш, используя нашу хэш-функцию. Теперь на руках мы имеем два числа: хэш шаблона и хэш прочитанного из текста, если эти два числа равны, то мы подробно сравниваем наш шаблон и то, что мы прочитали из текста, и тогда уже выносим вердикт о том, нашли ли мы шаблон в тексте, если же они не равны, то подробно рассматривать их смысла нет, так как хэш-функция дала ответ об их похожести. 
Алгоритм Рабина-Карпа подразумевает, что мы будем сдвигать наше "окошко" считывания на один символ, значит нам надо как-то оптимизировать процесс вычисления хэша, не будем же мы как глупые хомячки считать заново эти большие числа, для строки, которая отличается от придыдущей всего на одну букоуку. Воспользумся слудующим "**приколом**":

**hash = (hash - (s[0] mod q) / p** (здесь мы убрали из уже полученного хэша значение первого элемента подстроки, считанной из текста);
*/#Здесь должен был быть код, но мне лень, так что опишу словами. После того, как мы пересчитали хэш подстроки, мы удаляем первый символ из нашей подстроки и смещаем все оставшиеся элементы влево на 1. На конце строки у нас появилось вакантное место, куда мы считываем новый символ из текста.#/*

**hash = hash + (s[n-1] mod q) * p^(n-1)** (здесь мы добавили новый символ в значение хэша);

Таким образом мы избавили себя от необходимости пересчитывать весь хэш заново. Благодаря этому "**приколу**" данный подход иногда обзыват скользящим хэшированием.
А дальше бы проводим все те же сравнения, которые были описаны выше, пока не дойдём до конца текста.
## В чём фичи данного алгоритма, и где он нужен? ##
Вся крутость этого алгоритма раскрывается, когда необходимо найти в тексте вхождения множества разных шаблонов. Если же нам просто необходимо найти какое-то конкретное слово в тексте, то это обращайтесь по другому адресу, таким мы не занимаемся. В наилучшем и среднем случае время выполения алгоритма равно **O(n)**, в худшме же - **O(nm)**, где  **n** и **m** длины текста и шаблона соответственно, зависит скорость от выбора коэффицентов **p** и **q**. Чаще всего этот алгоритм встречается в системах антиплагиата.

Вроде бы на этом всё, больше ничего не знаю. Я умею только дышать и жаловаться на общагу №7.
Алгоритм Рабина-Карпа в 20 строк C-кода [здесь](https://www.youtube.com/watch?v=dQw4w9WgXcQ).
